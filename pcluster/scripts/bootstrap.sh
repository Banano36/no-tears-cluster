#!/usr/bin/env bash -l

# Note the -l above to get .bashrc and /etc/profile

exec &> >(tee -a "/tmp/BOOTSTRAP.log")
shopt -q login_shell && echo 'Login shell' || echo 'Not login shell'

# Force login shell
. /etc/profile

whoami > /tmp/BOOTSTRAP.WHOAMI
env >> /tmp/BOOTSTRAP.WHOAMI

#export VPC_ID=${1:-default}
#export MASTER_SUBNET_ID=${2:-default}
#export COMPUTE_SUBNET_ID=${3:-default}
#export SSH_KEY_ID=${1:-default}
#export PRIVATE_KEY_ARN=${2:-default}

#TODO:
#sudo pip-3.6 --disable-pip-version-check --no-cache-dir install aws-parallelcluster --upgrade
pip-3.6 --disable-pip-version-check --no-cache-dir install aws-parallelcluster --user

export AWS_DEFAULT_REGION=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone | rev | cut -c 2- | rev)

# Load the SSH Key generated by CloudFormation
aws secretsmanager get-secret-value --secret-id ${private_key_arn} --query SecretString --output text > ~/.ssh/${ssh_key_id}
chmod 600 ~/.ssh/${ssh_key_id}

# Automatically add ssh key into agent. we need to make the agent stop asking for a password
echo 'eval $(ssh-agent)' >> ~/.bashrc
echo "ssh-add ~/.ssh/${ssh_key_id}" >> ~/.bashrc

mkdir -p ~/.parallelcluster
cat > ~/.parallelcluster/config <<EOF
[global]
cluster_template = covid
update_check = true
sanity_check = true

[aws]
aws_region_name = ${AWS_DEFAULT_REGION}

[aliases]
ssh = ssh {CFN_USER}@{MASTER_IP} {ARGS}

[cluster covid]
key_name = ${ssh_key_id}
base_os = ubuntu1804
scheduler = slurm
master_instance_type = c5n.9xlarge
compute_instance_type = c5n.18xlarge
vpc_settings = public-private
#fsx_settings = fsx-scratch2
disable_hyperthreading = true
dcv_settings = dcv
#post_install = https://covid19hpc-quickstart-161153343288.s3.amazonaws.com/dev_user_data.sh
post_install = ${post_install_script_url}
post_install_args = "/shared/spack-0.13 /opt/slurm/log sacct.log"
initial_queue_size = 0
max_queue_size = 10
placement_group = DYNAMIC
master_root_volume_size = 200
compute_root_volume_size = 80
ebs_settings = myebs
cw_log_settings = cw-logs
enable_efa = compute

[ebs myebs]
volume_size = 500
shared_dir = /shared

[dcv mydcv]
enable = master

[fsx fsx-scratch2]
shared_dir = /scratch
storage_capacity = 1200
deployment_type = SCRATCH_2
import_path = s3://ebbollig-fsx-lustre-120988395753
export_path = s3://ebbollig-fsx-lustre-120988395753

#[fsx fsx]
#shared_dir = /fsx
#storage_capacity = 1200

[dcv dcv]
enable = master
port = 8443
access_from = 0.0.0.0/0

[cw_log cw-logs]
enable = false

[vpc public-private]
vpc_id = ${vpc_id}
master_subnet_id = ${master_subnet_id}
compute_subnet_id = ${compute_subnet_id}

EOF

which pcluster >> /tmp/BOOTSTRAP.WHOAMI
# Start the pcluster provisioning, but don't wait for it to complete.
pcluster create -t covid covid-cluster --nowait

echo "Finished" >> /tmp/BOOTSTRAP.WHOAMI
echo "Finished"
